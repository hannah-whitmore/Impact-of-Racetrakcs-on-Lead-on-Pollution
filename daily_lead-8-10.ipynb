{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from haversine import haversine, Unit\n",
    "import itertools\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in DFs and Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new DF with lat-longs from Google Maps\n",
    "tracks_df = pd.read_excel('../input_data/Nascar -Arca _1980_2020_updated.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_lead_df = pd.read_csv('../input_data/daily_lead_80_20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_lead_df['point'] = [(x, y) for x,y in zip(daily_lead_df['latitude'], daily_lead_df['longitude'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_lead_df['date'] = pd.to_datetime(daily_lead_df['date1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_lead_df = pd.read_pickle(\"../../21_6_7/notebooks/daily_lead_unique.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df['point'] = [(x, y) for x,y in zip(tracks_df['lat_Google_Maps'], tracks_df['long_Google_Maps'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df_4km = tracks_df.copy()\n",
    "tracks_df_50mi = tracks_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find All Stations Within X km of Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_points = list(filt_lead_df['point'])\n",
    "monitor_ids = list(filt_lead_df[\"monitorID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stations_within_thresh(point, points, monitor_ids, distance_thresh_min, distance_thresh_max, dist_unit):\n",
    "    \n",
    "    # finds distance between each track and every monitoring station\n",
    "    dist = []\n",
    "    if(dist_unit=='km'): # 1 indicates kilometers, else miles\n",
    "        for p in points:\n",
    "            x = round(haversine(point, p), 4)\n",
    "            dist.append(x)\n",
    "    elif(dist_unit=='mi'):\n",
    "        for p in points:\n",
    "            x = round(haversine(point, p, unit=Unit.MILES), 4)\n",
    "            dist.append(x)\n",
    "    else:\n",
    "        raise ValueError('wrong dist unit')\n",
    "    \n",
    "    idxs = [i for i,v in enumerate(dist) if (v >= distance_thresh_min and v <= distance_thresh_max)]\n",
    "\n",
    "    n_smallest_points = [points[idx] for idx in idxs] # monitor coordinates\n",
    "    n_smallest_ids = [monitor_ids[idx] for idx in idxs] # monitor IDs\n",
    "    n_smallest_dist = [dist[idx] for idx in idxs]\n",
    "\n",
    "    return n_smallest_points, n_smallest_ids, n_smallest_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_dist_thresh(df, distance_thresh_min, distance_thresh_max, dist_unit):\n",
    "    df = df.copy()\n",
    "    df['points_ids_dist'] = [get_stations_within_thresh(x, monitor_points, monitor_ids, distance_thresh_min, distance_thresh_max, dist_unit) \n",
    "                                              for x in df['point']]\n",
    "    dis =''\n",
    "    if (distance_thresh_max) == 50:\n",
    "        dis = '50mi'\n",
    "    elif (distance_thresh_max) == 6:\n",
    "        dis = '4-6km'\n",
    "    elif(distance_thresh_max) == 4:\n",
    "        dis = '4km'\n",
    "           \n",
    "    df[f'points_within_{dis}'] = df[\"points_ids_dist\"].apply(lambda x: x[0])\n",
    "    df['ids'] = df[\"points_ids_dist\"].apply(lambda x: x[1])\n",
    "    df['distances'] = df[\"points_ids_dist\"].apply(lambda x: x[2])\n",
    "    df['num_stations'] = [len(x) for x in df[f'points_within_{dis}']]\n",
    "    \n",
    "    df = df.query(\"num_stations != 0\").copy()\n",
    "    df[f'mean ({dist_unit})'] = [round(np.array(x).mean(),4) for x in df['distances'].values]\n",
    "    df[f'std ({dist_unit})'] = [round(pd.array(x).std(),4) for x in df['distances'].values]\n",
    "    df[f'max_dist ({dist_unit})'] = [max(x) for x in df['distances']]\n",
    "    df[f'min_dist ({dist_unit})'] = [min(x) for x in df['distances']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find All Stations Within 4K of Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_4km_df = (pass_dist_thresh(tracks_df_4km, 0, 4, 'km')\n",
    "                                  .drop(['points_ids_dist'], axis=1)\n",
    "                                  .reset_index(drop=True).copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Avg Pb Readings Pre and Post Races W Distance From Each Monitor to Track (km) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_race_dates = pd.read_excel('../input_data/race_dates_4_6.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_race_dates['Date'] = pd.to_datetime(all_race_dates['Date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_race_dates = all_race_dates.rename(columns = {'Unnamed: 0' : 'Track'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_names_04 = ['Autoclub Speedway, CA', 'Chicago Motor Speedway', 'Indiana State Fairgrounds (ARCA)',\n",
    "'Indianapolis Motor Speedway', 'Kansas Speedway', 'Nazareth','Bristol Speedway',\n",
    "\"Nashville Int'l Raceway/Nashville Fairgrounds Speedway\", 'Richmond']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_names_4km = ['Autoclub Speedway, CA', 'Bristol Speedway', 'Richmond']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tracks(track_names, all_race_dates): \n",
    "    race_dates_dfs = []\n",
    "    for x in track_names:\n",
    "        df = all_race_dates[all_race_dates['Track']== x].reset_index(drop=True)\n",
    "        race_dates_dfs.append(df)\n",
    "    return race_dates_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readings_pre_post_race(stations_df, daily_lead_df, check_date, ids):\n",
    "   \n",
    "    mask = (daily_lead_df['date']== check_date) \n",
    "   \n",
    "    df = daily_lead_df.loc[mask]\n",
    "\n",
    "    empty = True\n",
    "    out_ids = []\n",
    "    out_distances = []\n",
    "    #out_means = []    \n",
    "    \n",
    "    for ID in ids:\n",
    "        \n",
    "        lead_id_df = df[(df['monitorID']==ID)]\n",
    "        \n",
    "        if not lead_id_df.empty:\n",
    "            empty = False\n",
    "            \n",
    "            pb_lvl = round(lead_id_df['Pb_mean'].mean(),5)\n",
    "          \n",
    "            idx = ids.index(ID)\n",
    "            distance_from_track = stations_df['distances'].iloc[0][idx]\n",
    "            \n",
    "            out_ids.append(ID)\n",
    "            out_distances.append(distance_from_track)\n",
    "            \n",
    "#             dup_date = lead_id_df[lead_id_df[\"date\"].duplicated()]\n",
    "            \n",
    "#             if len(dup_date) > 0:\n",
    "#                 min_pb = dup_date['Pb_mean'].min()\n",
    "#                 idx = lead_id_df[lead_id_df['Pb_mean']==min_pb].index\n",
    "                \n",
    "#                 new_pb_df = lead_id_df.drop(index=idx)\n",
    "                \n",
    "#                 pb_lvl = round((new_pb_df['Pb_mean'].sum() + min_pb)  / (len(new_pb_df)+1),5)             \n",
    "            \n",
    "    if empty == False:\n",
    "        return out_ids, out_distances, pb_lvl\n",
    "    else:\n",
    "        return -1, -1, -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_each_race(race_dates_dfs, stations_df, daily_lead_df):\n",
    "    race_df_list = []\n",
    "        \n",
    "    days =  datetime.timedelta(days = 6)\n",
    "    one_week =  datetime.timedelta(days = 7)\n",
    "\n",
    "    for name, race_df in race_dates_dfs.groupby(\"Track\"):  # USE NAME \n",
    "        \n",
    "        race_dates = set(list(race_df[\"Date\"]))\n",
    "        \n",
    "        filt_stations_df = stations_df[stations_df[\"track name\"].str.contains(name[:4])].copy()\n",
    "        \n",
    "        if len(filt_stations_df)==0: ### race track not found in filt_stations_df,\n",
    "                                    # could be 0,1,2,3 of the 3 tracks based on monitors found within dist window\n",
    "            continue\n",
    "            \n",
    "        assert(len(filt_stations_df)==1) # one track at a time\n",
    "        \n",
    "        station_ids = filt_stations_df[\"ids\"].iloc[0]\n",
    "        \n",
    "        for race_date in race_dates:        \n",
    "\n",
    "            filt_race_date_df = race_df[race_df[\"Date\"]==race_date].copy()\n",
    "\n",
    "            \n",
    "            ## pre \n",
    "            \n",
    "            pre_dates = []\n",
    "            pre_ids = set()\n",
    "            pre_dist = set()\n",
    "            pre_pb = []\n",
    "\n",
    "            \n",
    "            check_date = race_date - one_week\n",
    "\n",
    "            for i in range(10):\n",
    "            \n",
    "                ids, distances, means = readings_pre_post_race(filt_stations_df, daily_lead_df, check_date, station_ids)     \n",
    "                if ids != -1:\n",
    "                    for x in ids:\n",
    "                        if x not in pre_ids:\n",
    "                            pre_ids.add(x)\n",
    "                    for x in distances:\n",
    "                        if x not in pre_dist:\n",
    "                            pre_dist.add(x)\n",
    "                            \n",
    "                    \n",
    "                    pre_pb.append(means)\n",
    "                    pre_dates.append(check_date.strftime('%Y-%m-%d'))\n",
    "                   \n",
    "                check_date = check_date - days\n",
    "                \n",
    "            \n",
    "            if ((len(filt_race_date_df)>0) & (len(pre_dates)>0)):\n",
    "                filt_race_date_df['pre_dates'] = [pre_dates] * len(filt_race_date_df)\n",
    "                \n",
    "                filt_race_date_df[\"pre_ids\"] = [pre_ids] * len(filt_race_date_df)\n",
    "                filt_race_date_df[\"pre_distances_km\"] = [pre_dist] * len(filt_race_date_df)\n",
    "                filt_race_date_df[\"pre_pb_readings\"] = [pre_pb] * len(filt_race_date_df)\n",
    "            \n",
    "                \n",
    "            post_dates = []\n",
    "            post_ids = set()\n",
    "            post_dist = set()\n",
    "            post_pb = []\n",
    "\n",
    "                \n",
    "            ## post \n",
    "            \n",
    "            check_date = race_date \n",
    "            for i in range(10):\n",
    "                ids, distances, means = readings_pre_post_race(filt_stations_df, daily_lead_df, check_date, station_ids)      \n",
    "                if ids != -1:\n",
    "                    for x in ids:\n",
    "                        if x not in post_ids:\n",
    "                            post_ids.add(x)\n",
    "                    for x in distances:\n",
    "                        if x not in post_dist:\n",
    "                            post_dist.add(x)\n",
    "                            \n",
    "                    post_pb.append(means)\n",
    "                    post_dates.append(check_date.strftime('%Y-%m-%d'))\n",
    "\n",
    "                check_date = check_date + days\n",
    "            if ((len(filt_race_date_df)>0) & (len(pre_dates)>0)):\n",
    "                filt_race_date_df[\"post_pb_readings\"] = [post_pb] * len(filt_race_date_df)\n",
    "                filt_race_date_df[\"post_dates\"] = [post_dates] * len(filt_race_date_df)\n",
    "                \n",
    "                \n",
    "                filt_race_date_df[\"post_ids\"] = [post_ids] * len(filt_race_date_df)\n",
    "                filt_race_date_df[\"post_distances_km\"] = [post_dist] * len(filt_race_date_df)\n",
    "                \n",
    "           \n",
    "          \n",
    "            race_df_list.append(filt_race_date_df)\n",
    "            \n",
    "           \n",
    "    out_df = pd.concat(race_df_list)\n",
    "    \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recaculate Post-lead means for :  0-4K, 0-5K, 0-6K, 0-7K 0-8K, 0-9K 0-10K, 10K - max for our 3 tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc6bf660accd4915962f135cb8581d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "filt_stations_4km_df = (tracks_df_4km[(tracks_df_4km[\"track name\"].str.contains(\"Auto Club Speedway\")) |\n",
    "                                        (tracks_df_4km[\"track name\"].str.contains(\"Bristol\")) |\n",
    "                                        (tracks_df_4km[\"track name\"].str.contains(\"Richmond\"))]\n",
    "                                        .reset_index(drop=True).copy())\n",
    "\n",
    "race_dates_df = pd.concat(get_tracks(track_names_4km, all_race_dates)).copy()\n",
    "\n",
    "all_dfs = {}\n",
    "all_df_list = []\n",
    "distances = [[0,1], [1,2], [2,3], [3,4], [4,5], [5,6], [6,7], [7,8], [8,9], [9,10],\n",
    "            [0,4], [0,5], [0,6], [0,7], [0,8], [0,9], [0, 10], [10,80]]\n",
    "\n",
    "for dist in tqdm(distances): \n",
    "\n",
    "    monitors_in_dist_df = (pass_dist_thresh(filt_stations_4km_df, dist[0], dist[1], 'km')\n",
    "                                  .drop(['points_ids_dist'], axis=1)\n",
    "                                  .reset_index(drop=True).copy())\n",
    "    if not monitors_in_dist_df.empty: \n",
    "        final_df = get_each_race(race_dates_df, monitors_in_dist_df, daily_lead_df)\n",
    "\n",
    "        final_df[\"distance_window\"] = [dist] * len(final_df)\n",
    "\n",
    "        all_df_list.append(final_df)\n",
    "\n",
    "        all_dfs[repr(dist)] = final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat(all_df_list).dropna().dropna().reset_index(drop=True)\n",
    "\n",
    "all_df[\"distance_window\"] = all_df[\"distance_window\"].apply(lambda x: repr(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filt_for_date(df, year1, year2):\n",
    "    filt = (df[(df['Date'] >= f\"{year1}-1-1\") & (df['Date']<= f\"{year2}-12-31\")])\n",
    "    filt_df = (filt.sort_values('Date')\n",
    "                    .drop_duplicates(subset='Date')\n",
    "                    .reset_index(drop=True))\n",
    "    \n",
    "    if len(filt_df)!=0:\n",
    "        assert(len(filt_df)<len(df))\n",
    "        return filt_df\n",
    "    else:\n",
    "        print(\"Empty DF filt for date\", year1, year2)\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### note:\n",
    "##### parentheses represent days before / after\n",
    "##### brackets represent distance window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All dfs to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DF filt for date 1990 2006\n",
      "[2, 3]\n",
      "Empty DF filt for date 2008 2015\n",
      "[2, 3]\n"
     ]
    }
   ],
   "source": [
    "for year1, year2 in [(1990,2006), (2008, 2015)]:\n",
    "    for name, df in all_df.groupby([\"distance_window\"]):\n",
    "        \n",
    "        filt_df = filt_for_date(df, year1, year2)\n",
    "        if len(filt_df)==0:\n",
    "            print(name)\n",
    "            continue\n",
    "        \n",
    "        out_name = f\"{year1}-{year2}_pre_post_race_lead_{name}.csv\"\n",
    "        out_path = \"pre_post_race_lead-2021-08-10/\" + out_name\n",
    "        \n",
    "        all_df_final = filt_df[filt_df.astype(str)['post_pb_readings'] != '[]']\n",
    "        \n",
    "        \n",
    "        filt_df_final = (all_df_final.drop(columns=['Cars', 'Winner(s)', 'St', 'Make / Model', 'Len', 'Sfc', 'Miles',\n",
    "                                              'Purse', 'Pole', 'Cau', 'Laps', 'Speed', 'LC'],axis=1)).reset_index(drop=True)\n",
    "\n",
    "        filt_df_final.to_csv(out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
